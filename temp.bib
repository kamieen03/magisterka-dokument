@misc{cohen2016,
    title={Group Equivariant Convolutional Networks},
    author={Taco S. Cohen and Max Welling},
    year={2016},
    eprint={1602.07576},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{bekkers2019,
    title={B-Spline CNNs on Lie Groups},
    author={Erik J Bekkers},
    year={2021},
    eprint={1909.12057},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{lieconv,
    title={Generalizing Convolutional Neural Networks for Equivariance to Lie Groups on Arbitrary Continuous Data},
    author={Marc Finzi and Samuel Stanton and Pavel Izmailov and Andrew Gordon Wilson},
    year={2020},
    eprint={2002.12880},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}

@MISC{gamma,
    author = {Andreas Siebert},
    title = {Differential Invariants under Gamma Correction},
    year = {2000}
}

@misc{deep_scale_spaces,
    title={Deep Scale-spaces: Equivariance Over Scale},
    author={Daniel E. Worrall and Max Welling},
    year={2019},
    eprint={1905.11697},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{scale_steerable,
    title={Scale-Equivariant Steerable Networks},
    author={Ivan Sosnovik and Michał Szmaja and Arnold Smeulders},
    year={2020},
    eprint={1910.11093},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{cohen2020general,
    title={A General Theory of Equivariant CNNs on Homogeneous Spaces},
    author={Taco Cohen and Mario Geiger and Maurice Weiler},
    year={2020},
    eprint={1811.02017},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{cohen_spherical_cnns,
    title={Spherical CNNs},
    author={Taco S. Cohen and Mario Geiger and Jonas Koehler and Max Welling},
    year={2018},
    eprint={1801.10130},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{kondor_trivedi,
    title={On the Generalization of Equivariance and Convolution in Neural Networks to the Action of Compact Groups},
    author={Risi Kondor and Shubhendu Trivedi},
    year={2018},
    eprint={1802.03690},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}

@misc{esteves_so3,
    title={Learning SO(3) Equivariant Representations with Spherical CNNs},
    author={Carlos Esteves and Christine Allen-Blanchette and Ameesh Makadia and Kostas Daniilidis},
    year={2018},
    eprint={1711.06721},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{hoogeboom2018hexaconv,
    title={HexaConv},
    author={Emiel Hoogeboom and Jorn W. T. Peters and Taco S. Cohen and Max Welling},
    year={2018},
    eprint={1803.02108},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{lie_transformer,
    title={LieTransformer: Equivariant self-attention for Lie Groups},
    author={Michael Hutchinson and Charline Le Lan and Sheheryar Zaidi and Emilien Dupont and Yee Whye Teh and Hyunjik Kim},
    year={2021},
    eprint={2012.10885},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{attentive_gcnn,
    title={Attentive Group Equivariant Convolutional Networks},
    author={David W. Romero and Erik J. Bekkers and Jakub M. Tomczak and Mark Hoogendoorn},
    year={2020},
    eprint={2002.03830},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{coattentive,
    title={Co-Attentive Equivariant Neural Networks: Focusing Equivariance On Transformations Co-Occurring In Data},
    author={David W. Romero and Mark Hoogendoorn},
    year={2020},
    eprint={1911.07849},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{augerino,
    title={Learning Invariances in Neural Networks},
    author={Gregory Benton and Marc Finzi and Pavel Izmailov and Andrew Gordon Wilson},
    year={2020},
    eprint={2010.11882},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}


@InProceedings{lorentz_kondor,
  title = 	 {{L}orentz Group Equivariant Neural Network for Particle Physics},
  author =       {Bogatskiy, Alexander and Anderson, Brandon and Offermann, Jan and Roussi, Marwah and Miller, David and Kondor, Risi},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {992--1002},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/bogatskiy20a/bogatskiy20a.pdf},
  url = 	 {http://proceedings.mlr.press/v119/bogatskiy20a.html},
  abstract = 	 {We present a neural network architecture that is fully equivariant with respect to transformations under the Lorentz group, a fundamental symmetry of space and time in physics. The architecture is based on the theory of the finite-dimensional representations of the Lorentz group and the equivariant nonlinearity involves the tensor product. For classification tasks in particle physics, we show that such an equivariant architecture leads to drastically simpler models that have relatively few learnable parameters and are much more physically interpretable than leading approaches that use CNNs and point cloud approaches. The performance of the network is tested on a public classification dataset [https://zenodo.org/record/2603256] for tagging top quark decays given energy-momenta of jet constituents produced in proton-proton collisions.}
}

@misc{torch_contrast,
    url = {https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.functional.adjust_contrast}
}

@misc{tf_contrast,
    url = {https://www.tensorflow.org/api_docs/python/tf/image/adjust_contrast}
}


@misc{imgaug_color_balance,
    url={https://imgaug.readthedocs.io/en/latest/source/api_augmenters_color.html#imgaug.augmenters.color.ChangeColorTemperature}
}

@misc{skimage_gamma,
    url =
    {https://scikit-image.org/docs/stable/api/skimage.exposure.html#adjust-gamma}
}

@misc{cv_gamma,
    url =
    {https://docs.opencv.org/4.5.2/d3/dc1/tutorial_basic_linear_transform.html}
}

@misc{torch_gamma,
    url =
    {https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.functional.adjust_gamma}
}

@TECHREPORT{cifar,
    author = {Alex Krizhevsky},
    title = {Learning multiple layers of features from tiny images},
    institution = {},
    year = {2009}
}


@inproceedings{stl10,
    title={ {An Analysis of Single Layer Networks in Unsupervised Feature Learning} },
    author={Coates, Adam and Ng, Andrew and Lee, Honglak},
    booktitle={AISTATS},
    year={2011},
    note = {\url{https://cs.stanford.edu/~acoates/papers/coatesleeng_aistats_2011.pdf} },
}

@misc{resnet,
    title={Deep Residual Learning for Image Recognition},
    author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
    year={2015},
    eprint={1512.03385},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{adamw,
    title={Decoupled Weight Decay Regularization},
    author={Ilya Loshchilov and Frank Hutter},
    year={2019},
    eprint={1711.05101},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@book{algebra,
    title={Abstract Algebra},
    author={Dummit, D.S. and Foote, R.M.},
    isbn={9780471433347},
    lccn={2003057652},
    url={https://books.google.pl/books?id=KJDBQgAACAAJ},
    year={2003},
    publisher={Wiley}
}

@book{lee_manifolds,
    title={Introduction to Smooth Manifolds},
    author={Lee, J.M.},
    isbn={9780387217529},
    lccn={2002070454},
    series={Graduate Texts in Mathematics},
    url={https://books.google.pl/books?id=w4bhBwAAQBAJ},
    year={2013},
    publisher={Springer New York}
}

